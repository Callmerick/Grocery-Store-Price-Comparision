{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Shop Fresh Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T20:36:28.014775Z",
     "start_time": "2020-10-04T20:36:24.618153Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/2098/categories/2155-fresh-fruit')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_fruits = []\n",
    "product_names_fruits = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_fruits)):\n",
    "    clean_product_names_fruits.append(product_names_fruits[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_fruits = clean_product_names_fruits[2:len(clean_product_names_fruits)+1]\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_fruits = []\n",
    "prices_fruits = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_fruits)):\n",
    "    clean_prices_fruits.append(prices_fruits[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_fruits = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_fruits = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_fruits)):\n",
    "            clean_starting_prices_fruits.append(starting_prices_fruits[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_fruits.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_fruits = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_fruits.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_fruits.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_fruits = []\n",
    "quantities_fruits = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_fruits)):\n",
    "    clean_quantities_fruits.append(quantities_fruits[i].text.strip())\n",
    "    \n",
    "#make a product classification column\n",
    "product_type = []\n",
    "product = \"Fresh Fruit\"\n",
    "for i in range(len(clean_product_names_fruits)):\n",
    "    product_type.append(product)\n",
    "\n",
    "#make a column to generate the date the data was pulled\n",
    "dates = []\n",
    "todays_date = datetime.date.today()\n",
    "for i in range(len(clean_product_names_fruits)):\n",
    "    dates.append(todays_date)\n",
    "    \n",
    "#make a column to generate the store name where the data is from\n",
    "store = []\n",
    "for i in range(len(clean_product_names_fruits)):\n",
    "    store.append('Stop and Shop')\n",
    "    \n",
    "#Create and outsheet dataframe, but clean the dollar sign off of prices\n",
    "Stop_and_Shop_Data_fruits = {'Date': dates,'Store':store,'Product Type':product_type, 'Product Name': clean_product_names_fruits,'Price':clean_prices_fruits,'Quantity Sold In':clean_quantities_fruits,'Sale on This Product?':clean_sale_yes_or_no_fruits,'If Sale, Original Price':clean_starting_prices_fruits}\n",
    "Stop_and_Shop_Dataframe_fruits = pd.DataFrame(data=Stop_and_Shop_Data_fruits)\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_fruits['Price'])):\n",
    "    Stop_and_Shop_Dataframe_fruits['Price'][i] = Stop_and_Shop_Dataframe_fruits['Price'][i][1:len(Stop_and_Shop_Dataframe_fruits['Price'])]\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_fruits['If Sale, Original Price'])):\n",
    "    if Stop_and_Shop_Dataframe_fruits['If Sale, Original Price'][i] != None:\n",
    "        Stop_and_Shop_Dataframe_fruits['If Sale, Original Price'][i] = Stop_and_Shop_Dataframe_fruits['If Sale, Original Price'][i][1:len(Stop_and_Shop_Dataframe_fruits['If Sale, Original Price'])]\n",
    "\n",
    "Stop_and_Shop_Dataframe_fruits.to_csv (r'C:\\Users\\Home\\Documents\\Web Analytics\\Group Project\\Python Exports\\Stop and Shop '+product+' '+str(todays_date)+'.csv', index = False, header=True)\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Shop Fresh Vegetables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/2098/categories/2334-fresh-vegetables')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_vegetables = []\n",
    "product_names_vegetables = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_vegetables)):\n",
    "    clean_product_names_vegetables.append(product_names_vegetables[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_vegetables = clean_product_names_vegetables[2:len(clean_product_names_vegetables)+1]\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_vegetables = []\n",
    "prices_vegetables = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_vegetables)):\n",
    "    clean_prices_vegetables.append(prices_vegetables[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_vegetables = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_vegetables = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_vegetables)):\n",
    "            clean_starting_prices_vegetables.append(starting_prices_vegetables[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_vegetables.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_vegetables = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_vegetables.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_vegetables.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_vegetables = []\n",
    "quantities_vegetables = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_vegetables)):\n",
    "    clean_quantities_vegetables.append(quantities_vegetables[i].text.strip())\n",
    "    \n",
    "#make a product classification column\n",
    "product_type = []\n",
    "product = \"Fresh Vegetables\"\n",
    "for i in range(len(clean_product_names_vegetables)):\n",
    "    product_type.append(product)\n",
    "\n",
    "#make a column to generate the date the data was pulled\n",
    "dates = []\n",
    "todays_date = datetime.date.today()\n",
    "for i in range(len(clean_product_names_vegetables)):\n",
    "    dates.append(todays_date)\n",
    "    \n",
    "#make a column to generate the store name where the data is from\n",
    "store = []\n",
    "for i in range(len(clean_product_names_vegetables)):\n",
    "    store.append('Stop and Shop')\n",
    "    \n",
    "#Create and outsheet dataframe,but clean the dollar sign off of prices\n",
    "Stop_and_Shop_Data_vegetables = {'Date': dates,'Store':store,'Product Type':product_type, 'Product Name': clean_product_names_vegetables,'Price':clean_prices_vegetables,'Quantity Sold In':clean_quantities_vegetables,'Sale on This Product?':clean_sale_yes_or_no_vegetables,'If Sale, Original Price':clean_starting_prices_vegetables}\n",
    "Stop_and_Shop_Dataframe_vegetables = pd.DataFrame(data=Stop_and_Shop_Data_vegetables)\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_vegetables['Price'])):\n",
    "    Stop_and_Shop_Dataframe_vegetables['Price'][i] = Stop_and_Shop_Dataframe_vegetables['Price'][i][1:len(Stop_and_Shop_Dataframe_vegetables['Price'])]\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_vegetables['If Sale, Original Price'])):\n",
    "    if Stop_and_Shop_Dataframe_vegetables['If Sale, Original Price'][i] != None:\n",
    "        Stop_and_Shop_Dataframe_vegetables['If Sale, Original Price'][i] = Stop_and_Shop_Dataframe_vegetables['If Sale, Original Price'][i][1:len(Stop_and_Shop_Dataframe_vegetables['If Sale, Original Price'])]\n",
    "\n",
    "\n",
    "Stop_and_Shop_Dataframe_vegetables.to_csv (r'C:\\Users\\Home\\Documents\\Web Analytics\\Group Project\\Python Exports\\Stop and Shop '+product+' '+str(todays_date)+'.csv', index = False, header=True)\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Shop Meat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/1563-meat')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_meat = []\n",
    "product_names_meat = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_meat)):\n",
    "    clean_product_names_meat.append(product_names_meat[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_meat = clean_product_names_meat[2:len(clean_product_names_meat)+1]\n",
    "clean_product_names_meat.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_meat = []\n",
    "prices_meat = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_meat)):\n",
    "    clean_prices_meat.append(prices_meat[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_meat = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_meat = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_meat)):\n",
    "            clean_starting_prices_meat.append(starting_prices_meat[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_meat.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_meat = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_meat.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_meat.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_meat = []\n",
    "quantities_meat = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_meat)):\n",
    "    clean_quantities_meat.append(quantities_meat[i].text.strip())\n",
    "    \n",
    "#make a product classification column\n",
    "product_type = []\n",
    "product = \"Meat\"\n",
    "for i in range(len(clean_product_names_meat)):\n",
    "    product_type.append(product)\n",
    "\n",
    "#make a column to generate the date the data was pulled\n",
    "dates = []\n",
    "todays_date = datetime.date.today()\n",
    "for i in range(len(clean_product_names_meat)):\n",
    "    dates.append(todays_date)\n",
    "    \n",
    "#make a column to generate the store name where the data is from\n",
    "store = []\n",
    "for i in range(len(clean_product_names_meat)):\n",
    "    store.append('Stop and Shop')\n",
    "    \n",
    "#Create and outsheet dataframe, but clean the dollar sign off of prices\n",
    "Stop_and_Shop_Data_meat = {'Date': dates,'Store':store,'Product Type':product_type, 'Product Name': clean_product_names_meat,'Price':clean_prices_meat,'Quantity Sold In':clean_quantities_meat,'Sale on This Product?':clean_sale_yes_or_no_meat,'If Sale, Original Price':clean_starting_prices_meat}\n",
    "Stop_and_Shop_Dataframe_meat = pd.DataFrame(data=Stop_and_Shop_Data_meat)\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_meat['Price'])):\n",
    "    Stop_and_Shop_Dataframe_meat['Price'][i] = Stop_and_Shop_Dataframe_meat['Price'][i][1:len(Stop_and_Shop_Dataframe_meat['Price'])]\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_meat['If Sale, Original Price'])):\n",
    "    if Stop_and_Shop_Dataframe_meat['If Sale, Original Price'][i] != None:\n",
    "        Stop_and_Shop_Dataframe_meat['If Sale, Original Price'][i] = Stop_and_Shop_Dataframe_meat['If Sale, Original Price'][i][1:len(Stop_and_Shop_Dataframe_meat['If Sale, Original Price'])]\n",
    "\n",
    "Stop_and_Shop_Dataframe_meat.to_csv (r'C:\\Users\\Home\\Documents\\Web Analytics\\Group Project\\Python Exports\\Stop and Shop '+product+' '+str(todays_date)+'.csv', index = False, header=True)\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Shop Seafood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "############################## First Run Through to Get Regular Fish ############################################\n",
    "\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/1633/categories/1634-fish')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_fish = []\n",
    "product_names_fish = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_fish)):\n",
    "    clean_product_names_fish.append(product_names_fish[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_fish = clean_product_names_fish[2:len(clean_product_names_fish)+1]\n",
    "\n",
    "#####clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_fish = []\n",
    "prices_fish = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_fish)):\n",
    "    clean_prices_fish.append(prices_fish[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_fish = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_fish = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_fish)):\n",
    "            clean_starting_prices_fish.append(starting_prices_fish[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_fish.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_fish = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_fish.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_fish.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_fish = []\n",
    "quantities_fish = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_fish)):\n",
    "    clean_quantities_fish.append(quantities_fish[i].text.strip())\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()\n",
    "    \n",
    "############################## Second Run Through to Get Shellfish and the Like ############################################\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/1633/categories/1663-shrimp-shellfish')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_shellfish = []\n",
    "product_names_shellfish = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_shellfish)):\n",
    "    clean_product_names_shellfish.append(product_names_shellfish[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_shellfish = clean_product_names_shellfish[2:len(clean_product_names_shellfish)+1]\n",
    "###clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_shellfish = []\n",
    "prices_shellfish = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_shellfish)):\n",
    "    clean_prices_shellfish.append(prices_shellfish[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_shellfish = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_shellfish = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_shellfish)):\n",
    "            clean_starting_prices_shellfish.append(starting_prices_shellfish[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_shellfish.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_shellfish = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_shellfish.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_shellfish.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_shellfish = []\n",
    "quantities_shellfish = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_shellfish)):\n",
    "    clean_quantities_shellfish.append(quantities_shellfish[i].text.strip())\n",
    "\n",
    "####################### Combined Fish and Shellfish Lists Together ############################\n",
    "clean_product_names_seafood = clean_product_names_fish + clean_product_names_shellfish\n",
    "clean_prices_seafood = clean_prices_fish + clean_prices_shellfish\n",
    "clean_starting_prices_seafood = clean_starting_prices_fish + clean_starting_prices_shellfish\n",
    "clean_sale_yes_or_no_seafood = clean_sale_yes_or_no_fish + clean_sale_yes_or_no_shellfish\n",
    "clean_quantities_seafood = clean_quantities_fish + clean_quantities_shellfish\n",
    "\n",
    "##########################  Proceed to Make Dataframe ############################\n",
    "\n",
    "#make a product classification column\n",
    "product_type = []\n",
    "product = \"Seafood\"\n",
    "for i in range(len(clean_product_names_seafood)):\n",
    "    product_type.append(product)\n",
    "\n",
    "#make a column to generate the date the data was pulled\n",
    "dates = []\n",
    "todays_date = datetime.date.today()\n",
    "for i in range(len(clean_product_names_seafood)):\n",
    "    dates.append(todays_date)\n",
    "    \n",
    "#make a column to generate the store name where the data is from\n",
    "store = []\n",
    "for i in range(len(clean_product_names_seafood)):\n",
    "    store.append('Stop and Shop')\n",
    "    \n",
    "#Create and outsheet dataframe, but clean the dollar sign off of prices\n",
    "Stop_and_Shop_Data_seafood = {'Date': dates,'Store':store,'Product Type':product_type, 'Product Name': clean_product_names_seafood,'Price':clean_prices_seafood,'Quantity Sold In':clean_quantities_seafood,'Sale on This Product?':clean_sale_yes_or_no_seafood,'If Sale, Original Price':clean_starting_prices_seafood}\n",
    "Stop_and_Shop_Dataframe_seafood = pd.DataFrame(data=Stop_and_Shop_Data_seafood)\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_seafood['Price'])):\n",
    "    Stop_and_Shop_Dataframe_seafood['Price'][i] = Stop_and_Shop_Dataframe_seafood['Price'][i][1:len(Stop_and_Shop_Dataframe_seafood['Price'])]\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_seafood['If Sale, Original Price'])):\n",
    "    if Stop_and_Shop_Dataframe_seafood['If Sale, Original Price'][i] != None:\n",
    "        Stop_and_Shop_Dataframe_seafood['If Sale, Original Price'][i] = Stop_and_Shop_Dataframe_seafood['If Sale, Original Price'][i][1:len(Stop_and_Shop_Dataframe_seafood['If Sale, Original Price'])]\n",
    "\n",
    "Stop_and_Shop_Dataframe_seafood.to_csv (r'C:\\Users\\Home\\Documents\\Web Analytics\\Group Project\\Python Exports\\Stop and Shop '+product+' '+str(todays_date)+'.csv', index = False, header=True)\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop and Shop Dairy (meaning milk, eggs, cheese, butter, juice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "############################## First Run Through to Get Milk ############################################\n",
    "\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/805/categories/827-milk')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon-size--xsmall')\n",
    "driver.execute_script('arguments[0].click();',X_button)\n",
    "#X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_milk = []\n",
    "product_names_milk = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_milk)):\n",
    "    clean_product_names_milk.append(product_names_milk[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_milk = clean_product_names_milk[2:len(clean_product_names_milk)+1]\n",
    "\n",
    "#####clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_milk = []\n",
    "prices_milk = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_milk)):\n",
    "    clean_prices_milk.append(prices_milk[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_milk = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_milk = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_milk)):\n",
    "            clean_starting_prices_milk.append(starting_prices_milk[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_milk.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_milk = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_milk.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_milk.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_milk = []\n",
    "quantities_milk = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_milk)):\n",
    "    clean_quantities_milk.append(quantities_milk[i].text.strip())\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()\n",
    "\n",
    "############################## Second Run Through to Get Eggs ############################################\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/805/categories/819-eggs-egg-substitutes')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_eggs = []\n",
    "product_names_eggs = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_eggs)):\n",
    "    clean_product_names_eggs.append(product_names_eggs[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_eggs = clean_product_names_eggs[2:len(clean_product_names_eggs)+1]\n",
    "###clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_eggs = []\n",
    "prices_eggs = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_eggs)):\n",
    "    clean_prices_eggs.append(prices_eggs[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_eggs = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_eggs = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_eggs)):\n",
    "            clean_starting_prices_eggs.append(starting_prices_eggs[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_eggs.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_eggs = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_eggs.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_eggs.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_eggs = []\n",
    "quantities_eggs = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_eggs)):\n",
    "    clean_quantities_eggs.append(quantities_eggs[i].text.strip())\n",
    "    \n",
    "#Close the webpage\n",
    "driver.close()\n",
    "    \n",
    "############################## Third Run Through to Get Cheese ############################################\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/805/categories/851-packaged-cheese')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_cheese = []\n",
    "product_names_cheese = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_cheese)):\n",
    "    clean_product_names_cheese.append(product_names_cheese[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_cheese = clean_product_names_cheese[2:len(clean_product_names_cheese)+1]\n",
    "\n",
    "#####clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_cheese = []\n",
    "prices_cheese = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_cheese)):\n",
    "    clean_prices_cheese.append(prices_cheese[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_cheese = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_cheese = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_cheese)):\n",
    "            clean_starting_prices_cheese.append(starting_prices_cheese[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_cheese.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_cheese = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_cheese.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_cheese.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_cheese = []\n",
    "quantities_cheese = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_cheese)):\n",
    "    clean_quantities_cheese.append(quantities_cheese[i].text.strip())\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()\n",
    "    \n",
    "############################## Fourth Run Through to Get Butter ############################################\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/805/categories/806-butter-margarine')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_butter = []\n",
    "product_names_butter = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_butter)):\n",
    "    clean_product_names_butter.append(product_names_butter[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_butter = clean_product_names_butter[2:len(clean_product_names_butter)+1]\n",
    "\n",
    "#####clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_butter = []\n",
    "prices_butter = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_butter)):\n",
    "    clean_prices_butter.append(prices_butter[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_butter = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_butter = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_butter)):\n",
    "            clean_starting_prices_butter.append(starting_prices_butter[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_butter.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_butter = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_butter.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_butter.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_butter = []\n",
    "quantities_butter = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_butter)):\n",
    "    clean_quantities_butter.append(quantities_butter[i].text.strip())\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()\n",
    "    \n",
    "############################## Fifth Run Through to Get Drinks ############################################\n",
    "#Open a new web browser.\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Open the web page that we want open and log in.\n",
    "driver.get('https://stopandshop.com/browse-aisles/categories/1/categories/805/categories/4715-refrigerated-juices-teas-coffee')\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"welcome to Stop and Shop\" window\n",
    "X_button = driver.find_element_by_class_name('vector-icon_outer-wrapper')\n",
    "X_button.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#Close out of the \"how are you shopping today?\" window\n",
    "X_button = driver.find_element_by_xpath('//*[@id=\"app\"]/div[1]/div/header/nav/div[4]/div/div[2]/button')\n",
    "X_button.click()\n",
    "\n",
    "#Grab the webpage as a BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "#Obtain Product Names and append to blank list\n",
    "clean_product_names_drinks = []\n",
    "product_names_drinks = soup.find_all('h3')\n",
    "\n",
    "for i in range(len(product_names_drinks)):\n",
    "    clean_product_names_drinks.append(product_names_drinks[i].text.strip())\n",
    "#This manual list slice gets rid of the two elements at the beginning of the list pulled from the website which are not products\n",
    "clean_product_names_drinks = clean_product_names_drinks[2:len(clean_product_names_drinks)+1]\n",
    "\n",
    "#####clean_product_names.remove('wallet-friendly organics')\n",
    "\n",
    "#Obtain Product Prices and append to blank list (this will accidentally disguise sales prices as regular prices)\n",
    "clean_prices_drinks = []\n",
    "prices_drinks = soup.find_all('span',class_='product-grid-cell_main-price')\n",
    "\n",
    "for i in range(len(prices_drinks)):\n",
    "    clean_prices_drinks.append(prices_drinks[i].text.strip())\n",
    "\n",
    "#If there there was a sale, obtain the orginal price and append to blank list\n",
    "clean_starting_prices_drinks = []\n",
    "big_HTML_container_1 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_1)):\n",
    "    if 'product-grid-cell_regular-price' in str(big_HTML_container_1[i]):\n",
    "        starting_prices_drinks = big_HTML_container_1[i].find_all('span',class_='product-grid-cell_regular-price product-grid-cell_regular-price--small')\n",
    "        for i in range(len(starting_prices_drinks)):\n",
    "            clean_starting_prices_drinks.append(starting_prices_drinks[i].text.strip())\n",
    "    else:\n",
    "        clean_starting_prices_drinks.append(None)  \n",
    "    \n",
    "#Obtain whether or not there was a sale and append to blank list\n",
    "clean_sale_yes_or_no_drinks = []\n",
    "big_HTML_container_2 = soup.find_all('div',class_='product-tile_content')\n",
    "\n",
    "for i in range(len(big_HTML_container_2)):\n",
    "    if 'flag_label flag_label--tomato' in str(big_HTML_container_2[i]):\n",
    "        clean_sale_yes_or_no_drinks.append('Sale')\n",
    "    else:\n",
    "        clean_sale_yes_or_no_drinks.append(None)\n",
    "\n",
    "#Obtain product quantities and append to blank list\n",
    "clean_quantities_drinks = []\n",
    "quantities_drinks = soup.find_all('span',class_='product-grid-cell_size')\n",
    "\n",
    "for i in range(len(quantities_drinks)):\n",
    "    clean_quantities_drinks.append(quantities_drinks[i].text.strip())\n",
    "\n",
    "####################### Combined Milk,Cheese Eggs, Butter, and Drinks Lists Together ############################\n",
    "clean_product_names_dairy = clean_product_names_milk + clean_product_names_cheese + clean_product_names_eggs + clean_product_names_butter +clean_product_names_drinks\n",
    "clean_prices_dairy = clean_prices_milk + clean_prices_cheese + clean_prices_eggs + clean_prices_butter + clean_prices_drinks\n",
    "clean_starting_prices_dairy = clean_starting_prices_milk + clean_starting_prices_cheese + clean_starting_prices_eggs + clean_starting_prices_butter + clean_starting_prices_drinks\n",
    "clean_sale_yes_or_no_dairy = clean_sale_yes_or_no_milk + clean_sale_yes_or_no_cheese + clean_sale_yes_or_no_eggs + clean_sale_yes_or_no_butter + clean_sale_yes_or_no_drinks\n",
    "clean_quantities_dairy = clean_quantities_milk + clean_quantities_cheese + clean_quantities_eggs + clean_quantities_butter + clean_quantities_drinks\n",
    "\n",
    "##########################  Proceed to Make Dataframe ############################\n",
    "\n",
    "#make a product classification column\n",
    "product_type = []\n",
    "product = \"Dairy\"\n",
    "for i in range(len(clean_product_names_dairy)):\n",
    "    product_type.append(product)\n",
    "\n",
    "#make a column to generate the date the data was pulled\n",
    "dates = []\n",
    "todays_date = datetime.date.today()\n",
    "for i in range(len(clean_product_names_dairy)):\n",
    "    dates.append(todays_date)\n",
    "    \n",
    "#make a column to generate the store name where the data is from\n",
    "store = []\n",
    "for i in range(len(clean_product_names_dairy)):\n",
    "    store.append('Stop and Shop')\n",
    "    \n",
    "#Create and outsheet dataframe, but clean the dollar sign off of price\n",
    "Stop_and_Shop_Data_dairy = {'Date': dates,'Store':store,'Product Type':product_type, 'Product Name': clean_product_names_dairy,'Price':clean_prices_dairy,'Quantity Sold In':clean_quantities_dairy,'Sale on This Product?':clean_sale_yes_or_no_dairy,'If Sale, Original Price':clean_starting_prices_dairy}\n",
    "Stop_and_Shop_Dataframe_dairy = pd.DataFrame(data=Stop_and_Shop_Data_dairy)\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_dairy['Price'])):\n",
    "    Stop_and_Shop_Dataframe_dairy['Price'][i] = Stop_and_Shop_Dataframe_dairy['Price'][i][1:len(Stop_and_Shop_Dataframe_dairy['Price'])]\n",
    "\n",
    "for i in range(len(Stop_and_Shop_Dataframe_dairy['If Sale, Original Price'])):\n",
    "    if Stop_and_Shop_Dataframe_dairy['If Sale, Original Price'][i] != None:\n",
    "        Stop_and_Shop_Dataframe_dairy['If Sale, Original Price'][i] = Stop_and_Shop_Dataframe_dairy['If Sale, Original Price'][i][1:len(Stop_and_Shop_Dataframe_dairy['If Sale, Original Price'])]\n",
    "\n",
    "Stop_and_Shop_Dataframe_dairy.to_csv (r'C:\\Users\\Home\\Documents\\Web Analytics\\Group Project\\Python Exports\\Stop and Shop '+product+' '+str(todays_date)+'.csv', index = False, header=True)\n",
    "\n",
    "#Close the webpage\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Resources**\n",
    "\n",
    "Selenium with Python: https://selenium-python.readthedocs.io/\n",
    "\n",
    "Selenium Python tutorial: https://www.geeksforgeeks.org/selenium-python-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
